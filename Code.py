# -*- coding: utf-8 -*-
"""SWIN Deployed .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vUZPWygTWjWTUjZb49J2oXs64S127kGw
"""

from glob import glob
import numpy as np
from sklearn.model_selection import train_test_split
import cv2
import torch
import torch.nn as nn
import torch.nn.functional
import torchvision
from torch.utils.data import TensorDataset
import math

!pip install streamlit pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
#

from google.colab import drive
drive.mount('/content/drive')

!pip install streamlit pyngrok --quiet

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# 
# import streamlit as st
# import nibabel as nib
# import tempfile
# import os
# import numpy as np
# import cv2
# import torch
# import gc
# import matplotlib.pyplot as plt
# from torch.utils.data import Dataset, DataLoader
# 
# # Function to load NIfTI file
# def load_nii_image(path):
#     nii = nib.load(path)
#     return nii.get_fdata()
# 
# # Preprocess a slice (resize + normalize)
# def preprocess_slice(slice, size=224):
#     slice = cv2.resize(slice, (size, size))
#     slice = slice / 255.0  # Normalize
#     return slice
# 
# # Custom Dataset Class
# class NiftiDataset(Dataset):
#     def __init__(self, image_paths, label_paths, size=224):
#         self.image_paths = sorted(image_paths)
#         self.label_paths = sorted(label_paths)
#         self.size = size
#         self.image_slices = []
#         self.label_slices = []
#         self._prepare_slices()
# 
#     def _prepare_slices(self):
#         for img_path, label_path in zip(self.image_paths, self.label_paths):
#             img_data = load_nii_image(img_path)
#             label_data = load_nii_image(label_path)
# 
#             assert img_data.shape == label_data.shape, f"Shape mismatch: {img_path} and {label_path}"
#             selected_slices = np.arange(49, 101)  # Select slices
# 
#             for i in selected_slices:
#                 img_slice = preprocess_slice(img_data[:, :, i], self.size)
#                 label_slice = preprocess_slice(label_data[:, :, i], self.size)
# 
#                 self.image_slices.append(img_slice)
#                 self.label_slices.append(label_slice)
# 
#         gc.collect()
# 
#     def __len__(self):
#         return len(self.image_slices)
# 
#     def __getitem__(self, idx):
#         image = np.expand_dims(self.image_slices[idx], axis=0)  # Shape: [1, 224, 224]
#         mask = np.expand_dims(self.label_slices[idx], axis=0)  # Shape: [1, 224, 224]
# 
#         image = torch.from_numpy(image.astype(np.float32))
#         mask = torch.from_numpy(mask.astype(np.float32))
#         return image, mask
# 
# # Function to visualize slices
# def visualize_slices(dataloader, num_slices=3):
#     batch = next(iter(dataloader))
#     X_batch, Y_batch = batch  # X: Image, Y: Mask
# 
#     # Convert tensors to NumPy
#     X_batch = X_batch.numpy()  # Shape: (B, C, H, W)
#     Y_batch = Y_batch.numpy()
# 
#     num_slices = min(num_slices, X_batch.shape[0])
#     random_indices = np.random.choice(range(X_batch.shape[0]), num_slices, replace=False)
# 
#     fig, axes = plt.subplots(num_slices, 2, figsize=(10, 10))
# 
#     for i, idx in enumerate(random_indices):
#         img = X_batch[idx, 0, :, :]
#         mask = Y_batch[idx, 0, :, :]
# 
#         axes[i, 0].imshow(img, cmap="gray")
#         axes[i, 1].imshow(mask, cmap="gray")
# 
#         axes[i, 0].set_title(f"Image Slice {idx}")
#         axes[i, 1].set_title(f"Segmentation Mask {idx}")
# 
#         axes[i, 0].axis("off")
#         axes[i, 1].axis("off")
# 
#     plt.tight_layout()
#     st.pyplot(fig)
# 
# # Streamlit UI
# st.title("ðŸ§  NIfTI Image Segmentation Viewer")
# 
# uploaded_images = st.file_uploader("ðŸ“‚ Upload NIfTI Images (.nii)", type=['nii'], accept_multiple_files=True)
# uploaded_labels = st.file_uploader("ðŸ“‚ Upload Corresponding Labels (.nii)", type=['nii'], accept_multiple_files=True)
# 
# if uploaded_images and uploaded_labels:
#     image_paths = []
#     label_paths = []
# 
#     for file in uploaded_images:
#         with tempfile.NamedTemporaryFile(delete=False, suffix=".nii") as temp_file:
#             temp_file.write(file.getvalue())
#             image_paths.append(temp_file.name)
# 
#     for file in uploaded_labels:
#         with tempfile.NamedTemporaryFile(delete=False, suffix=".nii") as temp_file:
#             temp_file.write(file.getvalue())
#             label_paths.append(temp_file.name)
# 
#     # Display shape of first uploaded file
#     first_image = nib.load(image_paths[0])
#     st.write("### ðŸ“ Shape of the NIfTI file:")
#     st.write(first_image.shape)
# 
#     # Create dataset and dataloader
#     dataset = NiftiDataset(image_paths, label_paths)
#     dataloader = DataLoader(dataset, batch_size=4, shuffle=True)
# 
#     # Number of slices selection
#     num_slices = st.slider("Number of Slices", 1, 5, 3)
# 
#     # Display button
#     if st.button("Show Random Slices"):
#         visualize_slices(dataloader, num_slices)
# 
#     # Cleanup temporary files after use
#     for path in image_paths + label_paths:
#         os.remove(path)

!streamlit run app.py &>/dev/null &

from pyngrok import ngrok
ngrok.set_auth_token("2yDc7paKN2wUMNInLkVX3HRJhSn_2CBovn7E67Z2F4MejUt19")

# Step 1: Ensure no previous ngrok tunnels are running
ngrok.kill()  # This will close any active tunnels

# Step 2: Start a new ngrok tunnel on port 8501
public_url = ngrok.connect(8501)

print(f"ðŸš€ Access the Streamlit App at: {public_url}")

